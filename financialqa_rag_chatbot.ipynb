{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0bf7c3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:25:33.825970Z",
          "iopub.status.busy": "2025-11-08T14:25:33.825262Z",
          "iopub.status.idle": "2025-11-08T14:26:52.216919Z",
          "shell.execute_reply": "2025-11-08T14:26:52.216009Z"
        },
        "papermill": {
          "duration": 78.398149,
          "end_time": "2025-11-08T14:26:52.218551",
          "exception": false,
          "start_time": "2025-11-08T14:25:33.820402",
          "status": "completed"
        },
        "tags": [],
        "id": "b0bf7c3f"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers faiss-cpu transformers accelerate langgraph >/dev/null 2>&1 || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e0b8db",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:26:52.227588Z",
          "iopub.status.busy": "2025-11-08T14:26:52.227125Z",
          "iopub.status.idle": "2025-11-08T14:27:23.165517Z",
          "shell.execute_reply": "2025-11-08T14:27:23.164745Z"
        },
        "papermill": {
          "duration": 30.944104,
          "end_time": "2025-11-08T14:27:23.166958",
          "exception": false,
          "start_time": "2025-11-08T14:26:52.222854",
          "status": "completed"
        },
        "tags": [],
        "id": "f4e0b8db",
        "outputId": "2af55208-ca3a-4fc0-af89-c03e3f56b394"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-08 14:27:08.915320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762612029.098574      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762612029.150546      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "import json, faiss, torch, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import List, Any, TypedDict, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16026b79",
      "metadata": {
        "papermill": {
          "duration": 0.00302,
          "end_time": "2025-11-08T14:27:23.173605",
          "exception": false,
          "start_time": "2025-11-08T14:27:23.170585",
          "status": "completed"
        },
        "tags": [],
        "id": "16026b79"
      },
      "source": [
        "# Inspect data & do preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63583f23",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:27:23.181293Z",
          "iopub.status.busy": "2025-11-08T14:27:23.180378Z",
          "iopub.status.idle": "2025-11-08T14:27:24.182405Z",
          "shell.execute_reply": "2025-11-08T14:27:24.181587Z"
        },
        "papermill": {
          "duration": 1.006937,
          "end_time": "2025-11-08T14:27:24.183570",
          "exception": false,
          "start_time": "2025-11-08T14:27:23.176633",
          "status": "completed"
        },
        "tags": [],
        "id": "63583f23",
        "outputId": "3d6ddd38-71d3-4d9c-bb7c-9dca23be06d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6251, 9)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pre_text</th>\n",
              "      <th>post_text</th>\n",
              "      <th>table</th>\n",
              "      <th>question</th>\n",
              "      <th>program</th>\n",
              "      <th>gold_inds</th>\n",
              "      <th>exe_ans</th>\n",
              "      <th>program_re</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADI/2009/page_49.pdf-1</td>\n",
              "      <td>[interest rate to a variable interest rate bas...</td>\n",
              "      <td>[fair value of forward exchange contracts afte...</td>\n",
              "      <td>[[, october 31 2009, november 1 2008], [fair v...</td>\n",
              "      <td>what is the the interest expense in 2009?</td>\n",
              "      <td>divide(100, 100), divide(3.8, #0)</td>\n",
              "      <td>{'text_1': 'if libor changes by 100 basis poin...</td>\n",
              "      <td>3.8</td>\n",
              "      <td>divide(3.8, divide(100, 100))</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABMD/2012/page_75.pdf-1</td>\n",
              "      <td>[abiomed , inc ., and subsidiaries notes to co...</td>\n",
              "      <td>[the remaining unrecognized compensation expen...</td>\n",
              "      <td>[[, number of shares ( in thousands ), weighte...</td>\n",
              "      <td>during the 2012 year , did the equity awards i...</td>\n",
              "      <td>multiply(607, 18.13), multiply(#0, const_1000)...</td>\n",
              "      <td>{'table_2': 'the granted of number of shares (...</td>\n",
              "      <td>yes</td>\n",
              "      <td>greater(multiply(multiply(607, 18.13), const_1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAL/2018/page_13.pdf-2</td>\n",
              "      <td>[the following table shows annual aircraft fue...</td>\n",
              "      <td>[as of december 31 , 2018 , we did not have an...</td>\n",
              "      <td>[[year, gallons, average priceper gallon, airc...</td>\n",
              "      <td>what was the total operating expenses in 2018 ...</td>\n",
              "      <td>divide(9896, 23.6%)</td>\n",
              "      <td>{'table_1': 'year the 2018 of gallons is 4447 ...</td>\n",
              "      <td>41932.20339</td>\n",
              "      <td>divide(9896, 23.6%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTC/2013/page_71.pdf-4</td>\n",
              "      <td>[the fair value of our grants receivable is de...</td>\n",
              "      <td>[in the third quarter of 2013 , we sold our sh...</td>\n",
              "      <td>[[( in millions ), dec 282013, dec 292012], [a...</td>\n",
              "      <td>what percentage of total cash and investments ...</td>\n",
              "      <td>divide(14001, 26302)</td>\n",
              "      <td>{'table_1': '( in millions ) the available-for...</td>\n",
              "      <td>0.53232</td>\n",
              "      <td>divide(14001, 26302)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ETR/2008/page_313.pdf-3</td>\n",
              "      <td>[entergy louisiana , llc management's financia...</td>\n",
              "      <td>[the retail electric price variance is primari...</td>\n",
              "      <td>[[, amount ( in millions )], [2007 net revenue...</td>\n",
              "      <td>what is the growth rate in net revenue in 2008?</td>\n",
              "      <td>subtract(959.2, 991.1), divide(#0, 991.1)</td>\n",
              "      <td>{'table_1': 'the 2007 net revenue of amount ( ...</td>\n",
              "      <td>-0.03219</td>\n",
              "      <td>divide(subtract(959.2, 991.1), 991.1)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id                                           pre_text  \\\n",
              "0   ADI/2009/page_49.pdf-1  [interest rate to a variable interest rate bas...   \n",
              "1  ABMD/2012/page_75.pdf-1  [abiomed , inc ., and subsidiaries notes to co...   \n",
              "2   AAL/2018/page_13.pdf-2  [the following table shows annual aircraft fue...   \n",
              "3  INTC/2013/page_71.pdf-4  [the fair value of our grants receivable is de...   \n",
              "4  ETR/2008/page_313.pdf-3  [entergy louisiana , llc management's financia...   \n",
              "\n",
              "                                           post_text  \\\n",
              "0  [fair value of forward exchange contracts afte...   \n",
              "1  [the remaining unrecognized compensation expen...   \n",
              "2  [as of december 31 , 2018 , we did not have an...   \n",
              "3  [in the third quarter of 2013 , we sold our sh...   \n",
              "4  [the retail electric price variance is primari...   \n",
              "\n",
              "                                               table  \\\n",
              "0  [[, october 31 2009, november 1 2008], [fair v...   \n",
              "1  [[, number of shares ( in thousands ), weighte...   \n",
              "2  [[year, gallons, average priceper gallon, airc...   \n",
              "3  [[( in millions ), dec 282013, dec 292012], [a...   \n",
              "4  [[, amount ( in millions )], [2007 net revenue...   \n",
              "\n",
              "                                            question  \\\n",
              "0          what is the the interest expense in 2009?   \n",
              "1  during the 2012 year , did the equity awards i...   \n",
              "2  what was the total operating expenses in 2018 ...   \n",
              "3  what percentage of total cash and investments ...   \n",
              "4    what is the growth rate in net revenue in 2008?   \n",
              "\n",
              "                                             program  \\\n",
              "0                  divide(100, 100), divide(3.8, #0)   \n",
              "1  multiply(607, 18.13), multiply(#0, const_1000)...   \n",
              "2                                divide(9896, 23.6%)   \n",
              "3                               divide(14001, 26302)   \n",
              "4          subtract(959.2, 991.1), divide(#0, 991.1)   \n",
              "\n",
              "                                           gold_inds      exe_ans  \\\n",
              "0  {'text_1': 'if libor changes by 100 basis poin...          3.8   \n",
              "1  {'table_2': 'the granted of number of shares (...          yes   \n",
              "2  {'table_1': 'year the 2018 of gallons is 4447 ...  41932.20339   \n",
              "3  {'table_1': '( in millions ) the available-for...      0.53232   \n",
              "4  {'table_1': 'the 2007 net revenue of amount ( ...     -0.03219   \n",
              "\n",
              "                                          program_re  \n",
              "0                      divide(3.8, divide(100, 100))  \n",
              "1  greater(multiply(multiply(607, 18.13), const_1...  \n",
              "2                                divide(9896, 23.6%)  \n",
              "3                               divide(14001, 26302)  \n",
              "4              divide(subtract(959.2, 991.1), 991.1)  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data structure:\n",
        "\n",
        "# \"pre_text\": the texts before the table;\n",
        "# \"post_text\": the text after the table;\n",
        "# \"table\": the table;\n",
        "# \"id\": unique example id. composed by the original report name plus example index for this report.\n",
        "\n",
        "# \"qa\": {\n",
        "#   \"question\": the question;\n",
        "#   \"program\": the reasoning program;\n",
        "#   \"gold_inds\": the gold supporting facts;\n",
        "#   \"exe_ans\": the gold execution result;\n",
        "#   \"program_re\": the reasoning program in nested format;\n",
        "# }\n",
        "\n",
        "# load in the train file\n",
        "train_pth = '/kaggle/input/question-answering-financial-data/train.json'\n",
        "with open(train_pth, 'r', encoding='utf-8') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "dataset = []\n",
        "for item in train_data:\n",
        "    dataset.append({\n",
        "        \"id\": item[\"id\"],\n",
        "        \"pre_text\": item[\"pre_text\"],\n",
        "        \"post_text\": item[\"post_text\"],\n",
        "        \"table\": item[\"table\"],\n",
        "        \"question\": item[\"qa\"][\"question\"],\n",
        "        \"program\": item[\"qa\"][\"program\"],\n",
        "        \"gold_inds\": item[\"qa\"][\"gold_inds\"],\n",
        "        \"exe_ans\": item[\"qa\"][\"exe_ans\"],\n",
        "        \"program_re\": item[\"qa\"][\"program_re\"],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c766f6d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:27:24.192280Z",
          "iopub.status.busy": "2025-11-08T14:27:24.191798Z",
          "iopub.status.idle": "2025-11-08T14:27:24.198722Z",
          "shell.execute_reply": "2025-11-08T14:27:24.197988Z"
        },
        "papermill": {
          "duration": 0.012268,
          "end_time": "2025-11-08T14:27:24.199791",
          "exception": false,
          "start_time": "2025-11-08T14:27:24.187523",
          "status": "completed"
        },
        "tags": [],
        "id": "c766f6d6",
        "outputId": "8032ff91-f2d0-41e4-c1dc-ccf3e3f94799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['For HOLX, what is the estimated number of outstanding shares based in the stated eps?',\n",
              " 'For AON, in 2015 what was the percentage change in the uncertain tax positions',\n",
              " 'For CDNS, what is the total return if $ 1000000 are invested in nasdaq composite in 2009 and sold in 2010?',\n",
              " 'For UNP, at december 31 , 2009 , what was the remaining compensation expense per share for the unvested awards?']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract some questions\n",
        "i = [415, 388, 104, 209]\n",
        "qs = [(df.loc[q][\"question\"], df.loc[q][\"id\"].split('/')[0] ) for q in i]\n",
        "questions = [f\"For {i[1]}, {i[0]}\" for i in qs]\n",
        "questions\n",
        "# These could be used for testing the RAG agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37865409",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:27:24.207513Z",
          "iopub.status.busy": "2025-11-08T14:27:24.207257Z",
          "iopub.status.idle": "2025-11-08T14:27:24.214732Z",
          "shell.execute_reply": "2025-11-08T14:27:24.214006Z"
        },
        "papermill": {
          "duration": 0.012648,
          "end_time": "2025-11-08T14:27:24.215864",
          "exception": false,
          "start_time": "2025-11-08T14:27:24.203216",
          "status": "completed"
        },
        "tags": [],
        "id": "37865409"
      },
      "outputs": [],
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self, chunk_size=200, overlap=50):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def join_list_text(self, text_list):\n",
        "        if isinstance(text_list, list):\n",
        "            return \" \".join(text_list)\n",
        "        return text_list\n",
        "\n",
        "    def table_to_text(self, table):\n",
        "        if not table:\n",
        "            return \"\"\n",
        "        rows = []\n",
        "        for row in table:\n",
        "            rows.append(\" | \".join([str(cell) for cell in row]))\n",
        "        return \"\\n\".join(rows)\n",
        "\n",
        "    def chunk_text(self, text):\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "        i = 0\n",
        "        while i < len(words):\n",
        "            chunk = \" \".join(words[i:i + self.chunk_size])\n",
        "            chunks.append(chunk)\n",
        "            i += self.chunk_size - self.overlap\n",
        "        return chunks\n",
        "\n",
        "    def transform(self, df):\n",
        "        \"\"\"Takes original FinQA dataframe, returns chunk dataframe for embeddings\"\"\"\n",
        "\n",
        "        # Preprocess text fields\n",
        "        df[\"pre_text_str\"] = df[\"pre_text\"].apply(self.join_list_text)\n",
        "        df[\"post_text_str\"] = df[\"post_text\"].apply(self.join_list_text)\n",
        "        df[\"full_text\"] = df[\"pre_text_str\"] + \" \" + df[\"post_text_str\"]\n",
        "        df[\"table_text\"] = df[\"table\"].apply(self.table_to_text)\n",
        "\n",
        "        # Build chunk list\n",
        "        all_chunks = []\n",
        "        for _, row in df.iterrows():\n",
        "            text_chunks = self.chunk_text(row[\"full_text\"])\n",
        "            table_chunks = self.chunk_text(row[\"table_text\"]) if row[\"table_text\"] else []\n",
        "\n",
        "            for chunk in text_chunks:\n",
        "                all_chunks.append({\n",
        "                    \"doc_id\": row[\"id\"],\n",
        "                    \"source\": \"text\",\n",
        "                    \"chunk\": chunk,\n",
        "                    \"question\": row[\"question\"]\n",
        "                })\n",
        "\n",
        "            for chunk in table_chunks:\n",
        "                all_chunks.append({\n",
        "                    \"doc_id\": row[\"id\"],\n",
        "                    \"source\": \"table\",\n",
        "                    \"chunk\": chunk,\n",
        "                    \"question\": row[\"question\"]\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(all_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0b2941",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:27:24.223734Z",
          "iopub.status.busy": "2025-11-08T14:27:24.223218Z",
          "iopub.status.idle": "2025-11-08T14:27:25.094318Z",
          "shell.execute_reply": "2025-11-08T14:27:25.093628Z"
        },
        "papermill": {
          "duration": 0.876076,
          "end_time": "2025-11-08T14:27:25.095443",
          "exception": false,
          "start_time": "2025-11-08T14:27:24.219367",
          "status": "completed"
        },
        "tags": [],
        "id": "7c0b2941",
        "outputId": "6e642403-6b99-4f73-af96-1872b8d6409c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chunks: 36074\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>source</th>\n",
              "      <th>chunk</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADI/2009/page_49.pdf-1</td>\n",
              "      <td>text</td>\n",
              "      <td>interest rate to a variable interest rate base...</td>\n",
              "      <td>what is the the interest expense in 2009?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADI/2009/page_49.pdf-1</td>\n",
              "      <td>text</td>\n",
              "      <td>relative to foreign currency exposures existin...</td>\n",
              "      <td>what is the the interest expense in 2009?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADI/2009/page_49.pdf-1</td>\n",
              "      <td>text</td>\n",
              "      <td>counterparties . while the contract or notiona...</td>\n",
              "      <td>what is the the interest expense in 2009?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADI/2009/page_49.pdf-1</td>\n",
              "      <td>text</td>\n",
              "      <td>unfavorable movement in foreign currency excha...</td>\n",
              "      <td>what is the the interest expense in 2009?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADI/2009/page_49.pdf-1</td>\n",
              "      <td>text</td>\n",
              "      <td>a potential change in sales levels or local cu...</td>\n",
              "      <td>what is the the interest expense in 2009?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   doc_id source  \\\n",
              "0  ADI/2009/page_49.pdf-1   text   \n",
              "1  ADI/2009/page_49.pdf-1   text   \n",
              "2  ADI/2009/page_49.pdf-1   text   \n",
              "3  ADI/2009/page_49.pdf-1   text   \n",
              "4  ADI/2009/page_49.pdf-1   text   \n",
              "\n",
              "                                               chunk  \\\n",
              "0  interest rate to a variable interest rate base...   \n",
              "1  relative to foreign currency exposures existin...   \n",
              "2  counterparties . while the contract or notiona...   \n",
              "3  unfavorable movement in foreign currency excha...   \n",
              "4  a potential change in sales levels or local cu...   \n",
              "\n",
              "                                    question  \n",
              "0  what is the the interest expense in 2009?  \n",
              "1  what is the the interest expense in 2009?  \n",
              "2  what is the the interest expense in 2009?  \n",
              "3  what is the the interest expense in 2009?  \n",
              "4  what is the the interest expense in 2009?  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor = TextPreprocessor(chunk_size=200, overlap=50)\n",
        "chunks_df = preprocessor.transform(df)\n",
        "print('chunks:', len(chunks_df))\n",
        "chunks_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d717c2b0",
      "metadata": {
        "papermill": {
          "duration": 0.003616,
          "end_time": "2025-11-08T14:27:25.102890",
          "exception": false,
          "start_time": "2025-11-08T14:27:25.099274",
          "status": "completed"
        },
        "tags": [],
        "id": "d717c2b0"
      },
      "source": [
        "# Build Embeddings & FAISS indices\n",
        "\n",
        "This part converts document chunks into vector embeddings using MiniLM, a light but effective transformer sentence-embedding model.\n",
        "\n",
        "Components:\n",
        "- Encoding every chunk into a dense vector\n",
        "- Building a FAISS IndexFlatL2 search index\n",
        "- Storing metadata\n",
        "- Define FAISS retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ce16d9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:27:25.110860Z",
          "iopub.status.busy": "2025-11-08T14:27:25.110484Z",
          "iopub.status.idle": "2025-11-08T14:28:45.995954Z",
          "shell.execute_reply": "2025-11-08T14:28:45.995086Z"
        },
        "papermill": {
          "duration": 80.890802,
          "end_time": "2025-11-08T14:28:45.997156",
          "exception": false,
          "start_time": "2025-11-08T14:27:25.106354",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "42b0576da96841419bd0575d6a682f60",
            "cd38a313177442068278100010f3943d",
            "5f58b8f0b38d498c9cce445477d6b7d4",
            "1e58ba9baf2c46d891fdf5554c6de1fd",
            "a60384a5a963453398f99e02f2796bd2",
            "96937a8cfee24116ae9444695fcf523a",
            "0279248f8c2c4f85ae7fdb185634332d",
            "796c388784b444c18ed291ba4bfdc31b",
            "91a9cf36a0224b4aa039377c891d7487",
            "b5c34e1a54e24ccfa55d43a99abe3389",
            "b3e15596c6004c119915d15339d20e5e",
            "1933271dc6fc480084df3756c038423e"
          ]
        },
        "id": "49ce16d9",
        "outputId": "5c4eb586-4de6-4101-f078-fd3776b24785"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42b0576da96841419bd0575d6a682f60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd38a313177442068278100010f3943d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f58b8f0b38d498c9cce445477d6b7d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e58ba9baf2c46d891fdf5554c6de1fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a60384a5a963453398f99e02f2796bd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96937a8cfee24116ae9444695fcf523a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0279248f8c2c4f85ae7fdb185634332d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "796c388784b444c18ed291ba4bfdc31b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91a9cf36a0224b4aa039377c891d7487",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5c34e1a54e24ccfa55d43a99abe3389",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3e15596c6004c119915d15339d20e5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1933271dc6fc480084df3756c038423e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/564 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index size: 36074\n"
          ]
        }
      ],
      "source": [
        "# Load embedding model\n",
        "embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Encode chunks\n",
        "embeddings = embedder.encode(\n",
        "    chunks_df[\"chunk\"].tolist(),\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "embeddings = np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "# Build FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "print(\"Index size:\", index.ntotal)\n",
        "\n",
        "# Store metadata outside FAISS\n",
        "metadata = chunks_df[[\"doc_id\", \"source\", \"question\", \"chunk\"]].reset_index(drop=True)\n",
        "docstore = metadata[\"chunk\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6211d3fb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:28:46.007846Z",
          "iopub.status.busy": "2025-11-08T14:28:46.007554Z",
          "iopub.status.idle": "2025-11-08T14:28:46.039182Z",
          "shell.execute_reply": "2025-11-08T14:28:46.038411Z"
        },
        "papermill": {
          "duration": 0.038137,
          "end_time": "2025-11-08T14:28:46.040299",
          "exception": false,
          "start_time": "2025-11-08T14:28:46.002162",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "8ba9eaa919864ee5947a692d739e7f37"
          ]
        },
        "id": "6211d3fb",
        "outputId": "a3fae571-57f2-4374-bdd4-43e4ee2d3f99"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ba9eaa919864ee5947a692d739e7f37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Doc: ALLE/2018/page_121.pdf-2\n",
            "Source: text\n",
            "Distance: 0.8385\n",
            "Chunk:\n",
            "note 18 2013 earnings per share ( eps ) basic eps is calculated by dividing net earnings attributable to allegion plc by the weighted-average number of ordinary shares outstanding for the applicable period . diluted eps is calculated after adjusting the denominator of the basic eps calculation for the effect of all potentially dilutive ordinary shares , which in the company 2019s case , includes shares issuable under share-based compensation plans . the following table summarizes the weighted-average number of ordinary shares outstanding for basic and diluted earnings per share calculations: . at december 31 , 2018 , 0.1 million stock options were excluded from the computation of weighted-average diluted shares outstanding because the effect of including these shares would have been anti-dilutive . note 19 2013 net revenues net revenues are recognized based on the satisfaction of performance obligations under the terms of a contract . a performance obligation is a promise in a contract to transfer control of a distinct product or to provide a service , or a bundle of products or services , to a customer , and is the unit of account under asc 606 . the company has two principal revenue streams , tangible\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Doc: ALLE/2018/page_121.pdf-1\n",
            "Source: text\n",
            "Distance: 0.8385\n",
            "Chunk:\n",
            "note 18 2013 earnings per share ( eps ) basic eps is calculated by dividing net earnings attributable to allegion plc by the weighted-average number of ordinary shares outstanding for the applicable period . diluted eps is calculated after adjusting the denominator of the basic eps calculation for the effect of all potentially dilutive ordinary shares , which in the company 2019s case , includes shares issuable under share-based compensation plans . the following table summarizes the weighted-average number of ordinary shares outstanding for basic and diluted earnings per share calculations: . at december 31 , 2018 , 0.1 million stock options were excluded from the computation of weighted-average diluted shares outstanding because the effect of including these shares would have been anti-dilutive . note 19 2013 net revenues net revenues are recognized based on the satisfaction of performance obligations under the terms of a contract . a performance obligation is a promise in a contract to transfer control of a distinct product or to provide a service , or a bundle of products or services , to a customer , and is the unit of account under asc 606 . the company has two principal revenue streams , tangible\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Doc: MO/2017/page_65.pdf-2\n",
            "Source: text\n",
            "Distance: 0.8665\n",
            "Chunk:\n",
            ") ( 24 ) ( 10 ) earnings for basic and diluted eps $ 10208 $ 14215 $ 5231 weighted-average shares for basic and diluted eps 1921 1952 1961 .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Doc: MO/2017/page_65.pdf-1\n",
            "Source: text\n",
            "Distance: 0.8665\n",
            "Chunk:\n",
            ") ( 24 ) ( 10 ) earnings for basic and diluted eps $ 10208 $ 14215 $ 5231 weighted-average shares for basic and diluted eps 1921 1952 1961 .\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def faiss_search(query, k=20):\n",
        "    \"\"\"\n",
        "    Search FAISS index and return top-k chunks with metadata.\n",
        "    \"\"\"\n",
        "    q_emb = embedder.encode([query]).astype(\"float32\") # make vector representation from the question\n",
        "    distances, indices = index.search(q_emb, k) # search for the top-k nearest vectors\n",
        "\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        metadata_row = metadata.iloc[idx].to_dict()\n",
        "        results.append({\n",
        "            \"chunk\": metadata_row[\"chunk\"],\n",
        "            \"doc_id\": metadata_row[\"doc_id\"],\n",
        "            \"source\": metadata_row[\"source\"],\n",
        "            \"distance\": float(dist)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Test it on Q1\n",
        "results = faiss_search(questions[0], k=4)\n",
        "for r in results:\n",
        "    print(f\"Doc: {r['doc_id']}\")\n",
        "    print(f\"Source: {r['source']}\")\n",
        "    print(f\"Distance: {r['distance']:.4f}\")\n",
        "    print(\"Chunk:\")\n",
        "    print(r[\"chunk\"])\n",
        "    print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf905ae0",
      "metadata": {
        "papermill": {
          "duration": 0.004603,
          "end_time": "2025-11-08T14:28:46.049857",
          "exception": false,
          "start_time": "2025-11-08T14:28:46.045254",
          "status": "completed"
        },
        "tags": [],
        "id": "cf905ae0"
      },
      "source": [
        "#  Build LangGraph agent pipeline\n",
        "This final chapter connects all components into a RAG pipeline.\n",
        "\n",
        "Components:\n",
        "- Flan-T5 LLM (text-to-text generator)\n",
        "- Cross-encoder MiniLM reranker\n",
        "- LangGraph workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfe6dd6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:28:46.060240Z",
          "iopub.status.busy": "2025-11-08T14:28:46.060047Z",
          "iopub.status.idle": "2025-11-08T14:29:02.229561Z",
          "shell.execute_reply": "2025-11-08T14:29:02.228734Z"
        },
        "papermill": {
          "duration": 16.176248,
          "end_time": "2025-11-08T14:29:02.231020",
          "exception": false,
          "start_time": "2025-11-08T14:28:46.054772",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "5a0addc30a6e42ec80cb830ebad553fd",
            "370ae084d9594944b75d40eea59e4ddb",
            "bf027b10bb944eb6b6a1efd364a09094",
            "32b1f11021e5445b81077d5ab8d70199",
            "520bc0517f754170a628031d63120de1",
            "fe2cd9858f724a0b9e56c6a4d79d8d48",
            "501b7438bc6248b391345c97b72fe29b",
            "fbd8388cd7ce4a8e88ae48e76fab51fb",
            "dced6440310e42f3a4cd8a243c4eeb43",
            "29a61e254c4b4784bbd296061a8deff6",
            "8c00fcbee93c4eb5ae851598cf2a2dad",
            "e07b33113b83479c93b823de02ffaebb",
            "b85ac2813ffd4d01922d33d61362e094"
          ]
        },
        "id": "bdfe6dd6",
        "outputId": "351724b8-affd-40db-b47c-47c5f3deaea9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a0addc30a6e42ec80cb830ebad553fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "370ae084d9594944b75d40eea59e4ddb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf027b10bb944eb6b6a1efd364a09094",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32b1f11021e5445b81077d5ab8d70199",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "520bc0517f754170a628031d63120de1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe2cd9858f724a0b9e56c6a4d79d8d48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "501b7438bc6248b391345c97b72fe29b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1614: UserWarning: The following device_map keys do not match any submodules in the model: ['decoder.embed_tokens']\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbd8388cd7ce4a8e88ae48e76fab51fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dced6440310e42f3a4cd8a243c4eeb43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29a61e254c4b4784bbd296061a8deff6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c00fcbee93c4eb5ae851598cf2a2dad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e07b33113b83479c93b823de02ffaebb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b85ac2813ffd4d01922d33d61362e094",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load LLM\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model_id = \"Qwen/Qwen1.5-1.8B-Chat\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
        "\n",
        "flan_model_id = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(flan_model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(flan_model_id, device_map=\"auto\")\n",
        "\n",
        "# Load Reranker\n",
        "rerank_model_id = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "rerank_tokenizer = AutoTokenizer.from_pretrained(rerank_model_id)\n",
        "rerank_model = AutoModelForSequenceClassification.from_pretrained(rerank_model_id).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c261686",
      "metadata": {
        "papermill": {
          "duration": 0.009048,
          "end_time": "2025-11-08T14:29:02.248975",
          "exception": false,
          "start_time": "2025-11-08T14:29:02.239927",
          "status": "completed"
        },
        "tags": [],
        "id": "4c261686"
      },
      "source": [
        "### LLM generator function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9966b389",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:29:02.266421Z",
          "iopub.status.busy": "2025-11-08T14:29:02.265585Z",
          "iopub.status.idle": "2025-11-08T14:29:02.272775Z",
          "shell.execute_reply": "2025-11-08T14:29:02.271954Z"
        },
        "papermill": {
          "duration": 0.018192,
          "end_time": "2025-11-08T14:29:02.274377",
          "exception": false,
          "start_time": "2025-11-08T14:29:02.256185",
          "status": "completed"
        },
        "tags": [],
        "id": "9966b389"
      },
      "outputs": [],
      "source": [
        "def build_prompt(question, context=None):\n",
        "    system = (\n",
        "        \"You are a helpful financial analysis assistant. \"\n",
        "        \"Use ONLY the provided context. \"\n",
        "        \"Do NOT repeat the context. \"\n",
        "        \"Do NOT provide any explanation. \"\n",
        "        \"If the answer is not in the context, just say 'Not found in provided reports.'\"\n",
        "    )\n",
        "    if context:\n",
        "        return f\"{system}\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    return f\"{system}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "def generate_llm_answer(prompt: str, max_tokens: int = 256, temperature: float = 0.2, top_p: float = 0.9):\n",
        "    \"\"\"\n",
        "    LLM generator function. Returns answer string.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "    )\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    answer = decoded.replace(prompt, \"\").strip() # remove prompt\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d04838e1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:29:02.293236Z",
          "iopub.status.busy": "2025-11-08T14:29:02.293013Z",
          "iopub.status.idle": "2025-11-08T14:29:02.302117Z",
          "shell.execute_reply": "2025-11-08T14:29:02.301364Z"
        },
        "papermill": {
          "duration": 0.019927,
          "end_time": "2025-11-08T14:29:02.303215",
          "exception": false,
          "start_time": "2025-11-08T14:29:02.283288",
          "status": "completed"
        },
        "tags": [],
        "id": "d04838e1"
      },
      "outputs": [],
      "source": [
        "class Reranker:\n",
        "    \"\"\"\n",
        "    Cross-encoder based reranker that scores query/doc pairs.\n",
        "    Return value: list of tuples (doc, score) sorted by decreasing relevance.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\", device: str = None):\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # CrossEncoder handles batching automatically\n",
        "        self.model = CrossEncoder(model_name, device=self.device)\n",
        "\n",
        "    def score(self, query: str, docs: List[str], batch_size: int = 16) -> List[float]:\n",
        "        \"\"\"Return raw scores for docs.\"\"\"\n",
        "        if not docs:\n",
        "            return []\n",
        "        pairs = [[query, d] for d in docs]\n",
        "        scores = self.model.predict(pairs, batch_size=batch_size, show_progress_bar=False)\n",
        "        return scores\n",
        "\n",
        "    def top_k(self, query: str, docs: List[str], k: int = 4, batch_size: int = 16) -> List[Tuple[str, float]]:\n",
        "        \"\"\"Returns the best k (doc, score) pairs sorted high->low.\"\"\"\n",
        "        if not docs:\n",
        "            return []\n",
        "        scores = self.score(query, docs, batch_size=batch_size)\n",
        "        doc_score_pairs = list(zip(docs, [float(s) for s in scores]))\n",
        "        doc_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "        return doc_score_pairs[:k]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc761753",
      "metadata": {
        "papermill": {
          "duration": 0.006054,
          "end_time": "2025-11-08T14:29:02.315172",
          "exception": false,
          "start_time": "2025-11-08T14:29:02.309118",
          "status": "completed"
        },
        "tags": [],
        "id": "bc761753"
      },
      "source": [
        "### LangGraph nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07aade74",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:29:02.330048Z",
          "iopub.status.busy": "2025-11-08T14:29:02.329680Z",
          "iopub.status.idle": "2025-11-08T14:29:02.345788Z",
          "shell.execute_reply": "2025-11-08T14:29:02.344842Z"
        },
        "papermill": {
          "duration": 0.024466,
          "end_time": "2025-11-08T14:29:02.347249",
          "exception": false,
          "start_time": "2025-11-08T14:29:02.322783",
          "status": "completed"
        },
        "tags": [],
        "id": "07aade74"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    question: str\n",
        "    plan: str\n",
        "    need_retrieval: bool\n",
        "    retrieved_chunks: List[str]\n",
        "    answer: str\n",
        "\n",
        "def planner_node(state: State):\n",
        "    \"\"\"Decision maker for RAG application.\"\"\"\n",
        "    q = state[\"question\"].lower()\n",
        "    finance_keywords = [\n",
        "        \"revenue\",\"income\",\"profit\",\"loss\",\"net\",\"year\",\"earnings\",\"balance\",\n",
        "        \"$\",\"million\",\"billion\",\"201\",\"202\"\n",
        "    ]\n",
        "    need = any(k in q for k in finance_keywords)\n",
        "    plan = \"RAG\" if need else \"Direct LLM\"\n",
        "    return {\"plan\": plan, \"need_retrieval\": need}\n",
        "\n",
        "def retriever_node(state):\n",
        "    \"\"\"Retriever: fast FAISS search -> many noisy hits -> rerank later.\"\"\"\n",
        "    results = faiss_search(state[\"question\"], k=20)\n",
        "    chunks = [r[\"chunk\"] for r in results]\n",
        "    return {\"retrieved_chunks\": chunks}\n",
        "\n",
        "def rerank_node(state):\n",
        "    \"\"\"Reranker: orders the chunks based on accuracy/confidence.\"\"\"\n",
        "    query = state[\"question\"]\n",
        "    docs = state.get(\"retrieved_chunks\", [])\n",
        "    ranked = reranker.top_k(query, docs, k=3)\n",
        "    top_docs = [d for d, s in ranked]\n",
        "    top_scores = [s for d, s in ranked]\n",
        "    avg_conf = sum(top_scores) / len(top_scores) if top_scores else 0.0\n",
        "\n",
        "    # If confidence is low, planner should try again\n",
        "    if avg_conf < 0.15:\n",
        "        print(\"Low confidence (avg:\", avg_conf, \")  consider fallback.\")\n",
        "        return {\"retrieved_chunks\": top_docs, \"retrieval_scores\": top_scores, \"low_confidence\": True}\n",
        "\n",
        "    return {\"retrieved_chunks\": top_docs, \"retrieval_scores\": top_scores, \"low_confidence\": False}\n",
        "\n",
        "def generator_node(state):\n",
        "    \"\"\"Generate answer based on retrieved context chunks.\"\"\"\n",
        "    context = \"\\n\\n\".join(state.get(\"retrieved_chunks\", []))\n",
        "    q = state[\"question\"]\n",
        "    prompt = build_prompt(q, context if context else None)\n",
        "    answer = generate_llm_answer(prompt)\n",
        "    return {\"answer\": answer}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53ed4b0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:29:02.363043Z",
          "iopub.status.busy": "2025-11-08T14:29:02.362395Z",
          "iopub.status.idle": "2025-11-08T14:29:03.053090Z",
          "shell.execute_reply": "2025-11-08T14:29:03.052195Z"
        },
        "papermill": {
          "duration": 0.701418,
          "end_time": "2025-11-08T14:29:03.055130",
          "exception": false,
          "start_time": "2025-11-08T14:29:02.353712",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "0f9b3795e62842d980cc71c4d2e1845e"
          ]
        },
        "id": "a53ed4b0",
        "outputId": "022399c3-13a4-4755-e085-ececee9b1728"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f9b3795e62842d980cc71c4d2e1845e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build LangGraph workflow\n",
        "reranker = Reranker(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Register nodes\n",
        "workflow.add_node(\"planner\", planner_node)\n",
        "workflow.add_node(\"retriever\", retriever_node)\n",
        "workflow.add_node(\"rerank\", rerank_node)\n",
        "workflow.add_node(\"generator\", generator_node)\n",
        "\n",
        "# Planner decides whether RAG is needed\n",
        "workflow.set_entry_point(\"planner\")\n",
        "workflow.add_conditional_edges(\"planner\", lambda s: \"retriever\" if s[\"need_retrieval\"] else \"generator\")\n",
        "\n",
        "# Normal RAG flow: retriever -> rerank -> generator\n",
        "workflow.add_edge(\"retriever\", \"rerank\")\n",
        "workflow.add_edge(\"rerank\", \"generator\")\n",
        "workflow.add_edge(\"generator\", END)\n",
        "\n",
        "# Compile graph\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8391ba61",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-08T14:29:03.073944Z",
          "iopub.status.busy": "2025-11-08T14:29:03.073098Z",
          "iopub.status.idle": "2025-11-08T14:29:05.990995Z",
          "shell.execute_reply": "2025-11-08T14:29:05.989778Z"
        },
        "papermill": {
          "duration": 2.929124,
          "end_time": "2025-11-08T14:29:05.992767",
          "exception": false,
          "start_time": "2025-11-08T14:29:03.063643",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "a6414080443e4c7281ea771f48b2cdb2",
            "7884d7a6d6d8498bb5f98a0a3e966231"
          ]
        },
        "id": "8391ba61",
        "outputId": "1fe2a65e-14cc-4538-ccb1-aebab9730835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original q: For HOLX, what is the estimated number of outstanding shares based in the stated eps?\n",
            "Found answer: Not found in provided reports\n",
            "\n",
            "Original q: For AON, in 2015 what was the percentage change in the uncertain tax positions\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6414080443e4c7281ea771f48b2cdb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found answer: Interest and penalties\n",
            "\n",
            "Original q: For CDNS, what is the total return if $ 1000000 are invested in nasdaq composite in 2009 and sold in 2010?\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7884d7a6d6d8498bb5f98a0a3e966231",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found answer: Not found in provided reports\n",
            "\n",
            "Original q: For UNP, at december 31 , 2009 , what was the remaining compensation expense per share for the unvested awards?\n",
            "Found answer: Not found in provided reports\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def rag_chat(query, debug=False):\n",
        "    \"\"\"Wrapper for RAG + LLM answer generation.\"\"\"\n",
        "    state = {\"question\": query}\n",
        "    final = None\n",
        "\n",
        "    for step in app.stream(state):\n",
        "        final = step\n",
        "        if debug:\n",
        "            print(\"\\n--- Step ---\")\n",
        "            print(step)\n",
        "\n",
        "    final_state = list(final.values())[-1]\n",
        "    return final_state.get(\"answer\", \"No answer generated.\")\n",
        "\n",
        "# Test it on the questions\n",
        "for q in questions:\n",
        "    print(f\"Original q: {q}\")\n",
        "    print(f\"Found answer: {rag_chat(q)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0475ca3",
      "metadata": {
        "papermill": {
          "duration": 0.012963,
          "end_time": "2025-11-08T14:29:06.023578",
          "exception": false,
          "start_time": "2025-11-08T14:29:06.010615",
          "status": "completed"
        },
        "tags": [],
        "id": "e0475ca3"
      },
      "source": [
        "### Conclusions & future improvements:\n",
        "- Flan-T5-Large/Qwen: too small model for quality answers\n",
        "    - decoder only model would be preferable\n",
        "    - a model that have seen more financial data\n",
        "- Tried Mistral 7-B, but I had version conflicts, that would take time to solve\n",
        "- More sophisticated LangGraph pipeline (multi-agent reasoning, self-verification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9385e0be",
      "metadata": {
        "papermill": {
          "duration": 0.012007,
          "end_time": "2025-11-08T14:29:06.047458",
          "exception": false,
          "start_time": "2025-11-08T14:29:06.035451",
          "status": "completed"
        },
        "tags": [],
        "id": "9385e0be"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 2034693,
          "sourceId": 3374493,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31154,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 218.981427,
      "end_time": "2025-11-08T14:29:09.299596",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-08T14:25:30.318169",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}